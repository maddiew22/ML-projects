{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in matches data\n",
    "matches = pd.read_csv(\"matches.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data clean up\n",
    "matches.dtypes\n",
    "matches[\"date\"] = pd.to_datetime(matches[\"date\"])\n",
    "matches[\"H/A_code\"] = matches[\"venue\"].astype(\"category\").cat.codes # 0 = away, 1 = home\n",
    "matches[\"opponent_code\"] = matches[\"opponent\"].astype(\"category\").cat.codes\n",
    "matches[\"hour\"] = matches[\"time\"].str.replace(\":.+\", \"\", regex=True).astype(\"int\") # extract hour only from the match time\n",
    "matches[\"day_code\"] = matches[\"date\"].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set target which model aims to predict\n",
    "matches[\"target\"] = (matches[\"result\"] == \"W\").astype(\"int\") # code wins as 1 and losses or draws as 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create random forest classifier\n",
    "model = RandomForestClassifier(n_estimators=50, min_samples_split=10, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recent_stats(group, stats, rolling_stats):\n",
    "    group = group.sort_values(\"date\")\n",
    "    # stats from 3 previous matches\n",
    "    rolling = group[stats].rolling(3, closed='left').mean()\n",
    "    group[rolling_stats] = rolling\n",
    "    # drop empty data (for example if only 2 previous matches have been played)\n",
    "    group = group.dropna(subset=rolling_stats)\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wc/x_1zt_1n1039tk89zhr_h2lh0000gn/T/ipykernel_10448/3255699945.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  recent_matches = matches.groupby(\"team\").apply(lambda x: recent_stats(x, stats, rolling_stats))\n"
     ]
    }
   ],
   "source": [
    "stats = [\"gf\", \"ga\", \"sh\", \"sot\", \"dist\", \"fk\", \"pk\", \"pkatt\"]\n",
    "rolling_stats = [f\"{s}_rolling\" for s in stats]\n",
    "recent_matches = matches.groupby(\"team\").apply(lambda x: recent_stats(x, stats, rolling_stats))\n",
    "recent_matches = recent_matches.droplevel(\"team\")\n",
    "recent_matches.index = range(recent_matches.shape[0]) # set unique indices\n",
    "recent_matches.columns = recent_matches.columns.str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(data, predictors):\n",
    "    # split into training and test data\n",
    "    training_set = data[data[\"date\"] < \"2022-01-01\"]\n",
    "    test_set  = data[data[\"date\"] >= \"2022-01-01\"]\n",
    "    model.fit(training_set[predictors], training_set[\"target\"]) \n",
    "    predictions = model.predict(test_set[predictors])\n",
    "    combined = pd.DataFrame(dict(actual=test_set[\"target\"], predictions=predictions))\n",
    "    precision = precision_score(test_set[\"target\"], predictions)\n",
    "    accuracy = accuracy_score(test_set[\"target\"], predictions)\n",
    "    return combined, precision, accuracy\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "predictors = recent_matches.columns[27:]\n",
    "combined, precision, accuracy = make_prediction(recent_matches, predictors)\n",
    "print(precision)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
